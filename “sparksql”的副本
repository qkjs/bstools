#####说明文档#####
	此文档用于sparksql的测试。
	
一.stage说明
---
	该stage为一个target stage，用于对上一个stage传来的json格式数据通过spark-thriftserver写入hive表中。
	数据应与hive表格式对应，因为数据可能不全，所以按照指定长度（可设置）的窗口对其进行均值计算后写入hive表中。
	比如，五批数据分别为
	{'var1':'10.0','var2':'10.0'},
	{'var1':'10.0'},
	{'var1':'10.0','var2':'10.0'},
	{'var2':'10.0'},
	{'var2','10.0'}，
	则最终写入为var1:6.0, var2:8.0

二.如何配置
---
在StreamStudio中实例化一个SparkSQL Target，并进行相应配置。

1.hive中创建表
通过spark beeline连接到hive，创建一张表：
create table test_hive3(var1 double, var2 double) stored as orc; 
注意:这里的hive表必须以orc格式存储

2.在stage上进行配置：
-Data Format：这里选择Text
（1）table：要写入的hive表，这里填写sparksql。
（2）url：spark-thriftserver的地址，这里填写jdbc:hive2://stream203.39.com:10016/default
（3）username：spark-thriftserver用户名，这里填写hdfs
（4）password：spark-thriftserver密码，这里不填
（5）window length：这里由用户填写，指定窗口长度

三.数据格式
---
{'var1':'20.0','var2':'21.0'}

四.如何验证？
---
在39上启动一个hive客户端，监控指定的hive表

